{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30249\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Embedding,Reshape,Input,Dot\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30249\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800167 100021 100021\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- UserIDs range between 1 and 6040 \n",
    "- MovieIDs range between 1 and 3952\n",
    "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
    "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
    "- Each user has at least 20 ratings\n",
    "'''\n",
    "rating_data=pd.read_csv(\"./ml-1m/ratings.dat\",header=None,names=[\"UserID\",\"MovieID\",\"Rating\",\"Timestamp\"],sep='::')\n",
    "rating_data=rating_data.sample(frac=1)\n",
    "#len(rating_data)\n",
    "traindata=rating_data[:int(len(rating_data)*8/10)]\n",
    "validdata=rating_data[int(len(rating_data)*8/10):int(len(rating_data)*9/10)]\n",
    "testdata=rating_data[int(len(rating_data)*9/10):]\n",
    "print(len(traindata),len(validdata),len(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 3952 800167\n"
     ]
    }
   ],
   "source": [
    "num_user = np.max(traindata[\"UserID\"])\n",
    "num_movie = np.max(traindata[\"MovieID\"])\n",
    "print(num_user,num_movie,len(traindata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def Recmand_model(num_user,num_movie,k):\n",
    "    input_uer = Input(shape=[None,],dtype=\"int32\")\n",
    "    print(input_uer)\n",
    "    model_uer = Embedding(num_user+1,k,input_length = 1)(input_uer)\n",
    "    model_uer = Reshape((k,))(model_uer)\n",
    "    \n",
    "    input_movie = Input(shape=[None,],dtype=\"int32\")\n",
    "    model_movie  = Embedding(num_movie+1,k,input_length = 1)(input_movie)\n",
    "    model_movie = Reshape((k,))(model_movie)\n",
    "    \n",
    "    out = Dot(1)([model_uer,model_movie])\n",
    "    model = Model(inputs=[input_uer,input_movie], outputs=out)\n",
    "    model.compile(loss='mse', optimizer='Adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, ?), dtype=int32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 100)       604100      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 100)       395300      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 100)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 100)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 999,400\n",
      "Trainable params: 999,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Recmand_model(num_user,num_movie,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = traindata[\"UserID\"].values\n",
    "train_movie = traindata[\"MovieID\"].values\n",
    "train_x = [train_user,train_movie]\n",
    "train_y = traindata[\"Rating\"].values\n",
    "\n",
    "valid_user = validdata[\"UserID\"].values\n",
    "valid_movie = validdata[\"MovieID\"].values\n",
    "valid_x = [valid_user,valid_movie]\n",
    "valid_y = validdata[\"Rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800167 samples, validate on 100021 samples\n",
      "Epoch 1/200\n",
      "800167/800167 [==============================] - 1s 1us/step - loss: 14.0753 - val_loss: 14.0467\n",
      "Epoch 2/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 14.0646 - val_loss: 14.0398\n",
      "Epoch 3/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 14.0454 - val_loss: 14.0144\n",
      "Epoch 4/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 14.0006 - val_loss: 13.9483\n",
      "Epoch 5/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 13.9046 - val_loss: 13.8113\n",
      "Epoch 6/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 13.7257 - val_loss: 13.5711\n",
      "Epoch 7/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 13.4317 - val_loss: 13.1986\n",
      "Epoch 8/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 12.9970 - val_loss: 12.6745\n",
      "Epoch 9/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 12.4078 - val_loss: 11.9942\n",
      "Epoch 10/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 11.6653 - val_loss: 11.1694\n",
      "Epoch 11/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 10.7869 - val_loss: 10.2237\n",
      "Epoch 12/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 9.8010 - val_loss: 9.1937\n",
      "Epoch 13/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 8.7464 - val_loss: 8.1217\n",
      "Epoch 14/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 7.6699 - val_loss: 7.0560\n",
      "Epoch 15/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 6.6177 - val_loss: 6.0386\n",
      "Epoch 16/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 5.6282 - val_loss: 5.1039\n",
      "Epoch 17/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 4.7358 - val_loss: 4.2829\n",
      "Epoch 18/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 3.9646 - val_loss: 3.5897\n",
      "Epoch 19/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 3.3241 - val_loss: 3.0256\n",
      "Epoch 20/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 2.8089 - val_loss: 2.5792\n",
      "Epoch 21/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 2.4051 - val_loss: 2.2327\n",
      "Epoch 22/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 2.0933 - val_loss: 1.9680\n",
      "Epoch 23/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.8566 - val_loss: 1.7674\n",
      "Epoch 24/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.6759 - val_loss: 1.6122\n",
      "Epoch 25/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.5351 - val_loss: 1.4900\n",
      "Epoch 26/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.4230 - val_loss: 1.3919\n",
      "Epoch 27/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.3328 - val_loss: 1.3128\n",
      "Epoch 28/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.2591 - val_loss: 1.2476\n",
      "Epoch 29/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.1981 - val_loss: 1.1935\n",
      "Epoch 30/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.1477 - val_loss: 1.1488\n",
      "Epoch 31/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.1056 - val_loss: 1.1112\n",
      "Epoch 32/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.0699 - val_loss: 1.0796\n",
      "Epoch 33/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.0398 - val_loss: 1.0528\n",
      "Epoch 34/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.0141 - val_loss: 1.0299\n",
      "Epoch 35/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9921 - val_loss: 1.0100\n",
      "Epoch 36/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9732 - val_loss: 0.9928\n",
      "Epoch 37/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9565 - val_loss: 0.9775\n",
      "Epoch 38/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9420 - val_loss: 0.9642\n",
      "Epoch 39/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9292 - val_loss: 0.9525\n",
      "Epoch 40/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9181 - val_loss: 0.9428\n",
      "Epoch 41/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9087 - val_loss: 0.9346\n",
      "Epoch 42/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9002 - val_loss: 0.9270\n",
      "Epoch 43/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8926 - val_loss: 0.9199\n",
      "Epoch 44/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8855 - val_loss: 0.9133\n",
      "Epoch 45/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8793 - val_loss: 0.9076\n",
      "Epoch 46/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8739 - val_loss: 0.9028\n",
      "Epoch 47/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8692 - val_loss: 0.8985\n",
      "Epoch 48/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8651 - val_loss: 0.8947\n",
      "Epoch 49/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8613 - val_loss: 0.8914\n",
      "Epoch 50/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8577 - val_loss: 0.8881\n",
      "Epoch 51/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8544 - val_loss: 0.8848\n",
      "Epoch 52/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8513 - val_loss: 0.8817\n",
      "Epoch 53/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8483 - val_loss: 0.8791\n",
      "Epoch 54/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8456 - val_loss: 0.8763\n",
      "Epoch 55/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8430 - val_loss: 0.8741\n",
      "Epoch 56/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8406 - val_loss: 0.8721\n",
      "Epoch 57/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8382 - val_loss: 0.8702\n",
      "Epoch 58/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8360 - val_loss: 0.8686\n",
      "Epoch 59/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8338 - val_loss: 0.8668\n",
      "Epoch 60/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8317 - val_loss: 0.8649\n",
      "Epoch 61/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8300 - val_loss: 0.8637\n",
      "Epoch 62/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8283 - val_loss: 0.8626\n",
      "Epoch 63/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8268 - val_loss: 0.8616\n",
      "Epoch 64/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8253 - val_loss: 0.8602\n",
      "Epoch 65/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8238 - val_loss: 0.8589\n",
      "Epoch 66/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8224 - val_loss: 0.8577\n",
      "Epoch 67/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8210 - val_loss: 0.8566\n",
      "Epoch 68/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8196 - val_loss: 0.8556\n",
      "Epoch 69/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8182 - val_loss: 0.8545\n",
      "Epoch 70/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8171 - val_loss: 0.8537\n",
      "Epoch 71/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8162 - val_loss: 0.8533\n",
      "Epoch 72/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8153 - val_loss: 0.8526\n",
      "Epoch 73/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8142 - val_loss: 0.8518\n",
      "Epoch 74/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8131 - val_loss: 0.8510\n",
      "Epoch 75/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8120 - val_loss: 0.8500\n",
      "Epoch 76/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8108 - val_loss: 0.8490\n",
      "Epoch 77/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8095 - val_loss: 0.8480\n",
      "Epoch 78/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8084 - val_loss: 0.8470\n",
      "Epoch 79/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8076 - val_loss: 0.8462\n",
      "Epoch 80/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8069 - val_loss: 0.8454\n",
      "Epoch 81/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8062 - val_loss: 0.8447\n",
      "Epoch 82/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8053 - val_loss: 0.8446\n",
      "Epoch 83/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8046 - val_loss: 0.8440\n",
      "Epoch 84/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8039 - val_loss: 0.8434\n",
      "Epoch 85/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8032 - val_loss: 0.8428\n",
      "Epoch 86/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8025 - val_loss: 0.8418\n",
      "Epoch 87/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8017 - val_loss: 0.8412\n",
      "Epoch 88/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8009 - val_loss: 0.8403\n",
      "Epoch 89/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8001 - val_loss: 0.8395\n",
      "Epoch 90/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7990 - val_loss: 0.8388\n",
      "Epoch 91/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7977 - val_loss: 0.8380\n",
      "Epoch 92/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7967 - val_loss: 0.8373\n",
      "Epoch 93/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7959 - val_loss: 0.8370\n",
      "Epoch 94/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7952 - val_loss: 0.8368\n",
      "Epoch 95/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7946 - val_loss: 0.8363\n",
      "Epoch 96/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7938 - val_loss: 0.8357\n",
      "Epoch 97/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7928 - val_loss: 0.8352\n",
      "Epoch 98/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7920 - val_loss: 0.8349\n",
      "Epoch 99/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7914 - val_loss: 0.8346\n",
      "Epoch 100/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7908 - val_loss: 0.8348\n",
      "Epoch 101/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7900 - val_loss: 0.8340\n",
      "Epoch 102/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7888 - val_loss: 0.8337\n",
      "Epoch 103/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7878 - val_loss: 0.8334\n",
      "Epoch 104/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7869 - val_loss: 0.8326\n",
      "Epoch 105/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7860 - val_loss: 0.8319\n",
      "Epoch 106/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7854 - val_loss: 0.8317\n",
      "Epoch 107/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7849 - val_loss: 0.8314\n",
      "Epoch 108/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7842 - val_loss: 0.8312\n",
      "Epoch 109/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7836 - val_loss: 0.8314\n",
      "Epoch 110/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7834 - val_loss: 0.8311\n",
      "Epoch 111/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7828 - val_loss: 0.8306\n",
      "Epoch 112/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7816 - val_loss: 0.8299\n",
      "Epoch 113/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7805 - val_loss: 0.8294\n",
      "Epoch 114/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7794 - val_loss: 0.8288\n",
      "Epoch 115/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7783 - val_loss: 0.8286\n",
      "Epoch 116/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7775 - val_loss: 0.8282\n",
      "Epoch 117/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7769 - val_loss: 0.8277\n",
      "Epoch 118/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7760 - val_loss: 0.8272\n",
      "Epoch 119/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7755 - val_loss: 0.8273\n",
      "Epoch 120/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7750 - val_loss: 0.8271\n",
      "Epoch 121/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7744 - val_loss: 0.8269\n",
      "Epoch 122/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7741 - val_loss: 0.8267\n",
      "Epoch 123/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7736 - val_loss: 0.8260\n",
      "Epoch 124/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7726 - val_loss: 0.8254\n",
      "Epoch 125/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7714 - val_loss: 0.8247\n",
      "Epoch 126/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7703 - val_loss: 0.8241\n",
      "Epoch 127/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7693 - val_loss: 0.8240\n",
      "Epoch 128/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7689 - val_loss: 0.8241\n",
      "Epoch 129/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7685 - val_loss: 0.8238\n",
      "Epoch 130/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7678 - val_loss: 0.8236\n",
      "Epoch 131/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7673 - val_loss: 0.8235\n",
      "Epoch 132/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7668 - val_loss: 0.8233\n",
      "Epoch 133/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7662 - val_loss: 0.8232\n",
      "Epoch 134/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7656 - val_loss: 0.8227\n",
      "Epoch 135/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7649 - val_loss: 0.8221\n",
      "Epoch 136/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7643 - val_loss: 0.8219\n",
      "Epoch 137/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7635 - val_loss: 0.8217\n",
      "Epoch 138/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7627 - val_loss: 0.8213\n",
      "Epoch 139/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7619 - val_loss: 0.8211\n",
      "Epoch 140/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7614 - val_loss: 0.8212\n",
      "Epoch 141/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7608 - val_loss: 0.8208\n",
      "Epoch 142/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7602 - val_loss: 0.8203\n",
      "Epoch 143/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7592 - val_loss: 0.8196\n",
      "Epoch 144/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7583 - val_loss: 0.8190\n",
      "Epoch 145/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7574 - val_loss: 0.8186\n",
      "Epoch 146/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7567 - val_loss: 0.8180\n",
      "Epoch 147/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7560 - val_loss: 0.8175\n",
      "Epoch 148/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7554 - val_loss: 0.8172\n",
      "Epoch 149/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7547 - val_loss: 0.8169\n",
      "Epoch 150/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7537 - val_loss: 0.8161\n",
      "Epoch 151/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7527 - val_loss: 0.8157\n",
      "Epoch 152/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7520 - val_loss: 0.8159\n",
      "Epoch 153/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7516 - val_loss: 0.8158\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_x,train_y,batch_size = 100000,epochs =200,callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=0)],validation_data=(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=model.predict([testdata[\"UserID\"].values,testdata[\"MovieID\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100021/100021 [==============================] - 3s 31us/step\n"
     ]
    }
   ],
   "source": [
    "test=model.evaluate([testdata[\"UserID\"].values,testdata[\"MovieID\"].values],testdata[\"Rating\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323691818606423"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 绘制训练 & 验证的准确率值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig(\"./modle_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5005, 4983, 4785, ..., 4868, 4907, 5530], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
