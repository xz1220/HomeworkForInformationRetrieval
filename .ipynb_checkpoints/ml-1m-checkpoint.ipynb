{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30249\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Embedding,Reshape,Input,Dot\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30249\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800167 100021 100021\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- UserIDs range between 1 and 6040 \n",
    "- MovieIDs range between 1 and 3952\n",
    "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
    "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
    "- Each user has at least 20 ratings\n",
    "'''\n",
    "rating_data=pd.read_csv(\"./ml-1m/ratings.dat\",header=None,names=[\"UserID\",\"MovieID\",\"Rating\",\"Timestamp\"],sep='::')\n",
    "rating_data=rating_data.sample(frac=1)\n",
    "#len(rating_data)\n",
    "traindata=rating_data[:int(len(rating_data)*8/10)]\n",
    "validdata=rating_data[int(len(rating_data)*8/10):int(len(rating_data)*9/10)]\n",
    "testdata=rating_data[int(len(rating_data)*9/10):]\n",
    "print(len(traindata),len(validdata),len(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 3952 800167\n"
     ]
    }
   ],
   "source": [
    "num_user = np.max(traindata[\"UserID\"])\n",
    "num_movie = np.max(traindata[\"MovieID\"])\n",
    "print(num_user,num_movie,len(traindata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def Recmand_model(num_user,num_movie,k):\n",
    "    input_uer = Input(shape=[None,],dtype=\"int32\")\n",
    "    print(input_uer)\n",
    "    model_uer = Embedding(num_user+1,k,input_length = 1)(input_uer)\n",
    "    model_uer = Reshape((k,))(model_uer)\n",
    "    \n",
    "    input_movie = Input(shape=[None,],dtype=\"int32\")\n",
    "    model_movie  = Embedding(num_movie+1,k,input_length = 1)(input_movie)\n",
    "    model_movie = Reshape((k,))(model_movie)\n",
    "    \n",
    "    out = Dot(1)([model_uer,model_movie])\n",
    "    model = Model(inputs=[input_uer,input_movie], outputs=out)\n",
    "    model.compile(loss='mse', optimizer='Adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, ?), dtype=int32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 100)       604100      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 100)       395300      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 100)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 100)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 999,400\n",
      "Trainable params: 999,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Recmand_model(num_user,num_movie,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = traindata[\"UserID\"].values\n",
    "train_movie = traindata[\"MovieID\"].values\n",
    "train_x = [train_user,train_movie]\n",
    "train_y = traindata[\"Rating\"].values\n",
    "\n",
    "valid_user = validdata[\"UserID\"].values\n",
    "valid_movie = validdata[\"MovieID\"].values\n",
    "valid_x = [valid_user,valid_movie]\n",
    "valid_y = validdata[\"Rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800167 samples, validate on 100021 samples\n",
      "Epoch 1/200\n",
      "800167/800167 [==============================] - 1s 1us/step - loss: 14.0753 - val_loss: 14.0467\n",
      "Epoch 2/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 14.0646 - val_loss: 14.0398\n",
      "Epoch 3/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 14.0454 - val_loss: 14.0144\n",
      "Epoch 4/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 14.0006 - val_loss: 13.9483\n",
      "Epoch 5/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 13.9046 - val_loss: 13.8113\n",
      "Epoch 6/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 13.7257 - val_loss: 13.5711\n",
      "Epoch 7/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 13.4317 - val_loss: 13.1986\n",
      "Epoch 8/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 12.9970 - val_loss: 12.6745\n",
      "Epoch 9/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 12.4078 - val_loss: 11.9942\n",
      "Epoch 10/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 11.6653 - val_loss: 11.1694\n",
      "Epoch 11/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 10.7869 - val_loss: 10.2237\n",
      "Epoch 12/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 9.8010 - val_loss: 9.1937\n",
      "Epoch 13/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 8.7464 - val_loss: 8.1217\n",
      "Epoch 14/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 7.6699 - val_loss: 7.0560\n",
      "Epoch 15/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 6.6177 - val_loss: 6.0386\n",
      "Epoch 16/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 5.6282 - val_loss: 5.1039\n",
      "Epoch 17/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 4.7358 - val_loss: 4.2829\n",
      "Epoch 18/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 3.9646 - val_loss: 3.5897\n",
      "Epoch 19/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 3.3241 - val_loss: 3.0256\n",
      "Epoch 20/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 2.8089 - val_loss: 2.5792\n",
      "Epoch 21/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 2.4051 - val_loss: 2.2327\n",
      "Epoch 22/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 2.0933 - val_loss: 1.9680\n",
      "Epoch 23/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.8566 - val_loss: 1.7674\n",
      "Epoch 24/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.6759 - val_loss: 1.6122\n",
      "Epoch 25/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.5351 - val_loss: 1.4900\n",
      "Epoch 26/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.4230 - val_loss: 1.3919\n",
      "Epoch 27/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.3328 - val_loss: 1.3128\n",
      "Epoch 28/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.2591 - val_loss: 1.2476\n",
      "Epoch 29/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.1981 - val_loss: 1.1935\n",
      "Epoch 30/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.1477 - val_loss: 1.1488\n",
      "Epoch 31/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.1056 - val_loss: 1.1112\n",
      "Epoch 32/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.0699 - val_loss: 1.0796\n",
      "Epoch 33/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.0398 - val_loss: 1.0528\n",
      "Epoch 34/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 1.0141 - val_loss: 1.0299\n",
      "Epoch 35/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9921 - val_loss: 1.0100\n",
      "Epoch 36/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9732 - val_loss: 0.9928\n",
      "Epoch 37/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9565 - val_loss: 0.9775\n",
      "Epoch 38/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9420 - val_loss: 0.9642\n",
      "Epoch 39/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9292 - val_loss: 0.9525\n",
      "Epoch 40/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9181 - val_loss: 0.9428\n",
      "Epoch 41/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9087 - val_loss: 0.9346\n",
      "Epoch 42/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.9002 - val_loss: 0.9270\n",
      "Epoch 43/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8926 - val_loss: 0.9199\n",
      "Epoch 44/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8855 - val_loss: 0.9133\n",
      "Epoch 45/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8793 - val_loss: 0.9076\n",
      "Epoch 46/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8739 - val_loss: 0.9028\n",
      "Epoch 47/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8692 - val_loss: 0.8985\n",
      "Epoch 48/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8651 - val_loss: 0.8947\n",
      "Epoch 49/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8613 - val_loss: 0.8914\n",
      "Epoch 50/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8577 - val_loss: 0.8881\n",
      "Epoch 51/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8544 - val_loss: 0.8848\n",
      "Epoch 52/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8513 - val_loss: 0.8817\n",
      "Epoch 53/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8483 - val_loss: 0.8791\n",
      "Epoch 54/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8456 - val_loss: 0.8763\n",
      "Epoch 55/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8430 - val_loss: 0.8741\n",
      "Epoch 56/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8406 - val_loss: 0.8721\n",
      "Epoch 57/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8382 - val_loss: 0.8702\n",
      "Epoch 58/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8360 - val_loss: 0.8686\n",
      "Epoch 59/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8338 - val_loss: 0.8668\n",
      "Epoch 60/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8317 - val_loss: 0.8649\n",
      "Epoch 61/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8300 - val_loss: 0.8637\n",
      "Epoch 62/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8283 - val_loss: 0.8626\n",
      "Epoch 63/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8268 - val_loss: 0.8616\n",
      "Epoch 64/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8253 - val_loss: 0.8602\n",
      "Epoch 65/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8238 - val_loss: 0.8589\n",
      "Epoch 66/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8224 - val_loss: 0.8577\n",
      "Epoch 67/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8210 - val_loss: 0.8566\n",
      "Epoch 68/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8196 - val_loss: 0.8556\n",
      "Epoch 69/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8182 - val_loss: 0.8545\n",
      "Epoch 70/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8171 - val_loss: 0.8537\n",
      "Epoch 71/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8162 - val_loss: 0.8533\n",
      "Epoch 72/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8153 - val_loss: 0.8526\n",
      "Epoch 73/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8142 - val_loss: 0.8518\n",
      "Epoch 74/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8131 - val_loss: 0.8510\n",
      "Epoch 75/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8120 - val_loss: 0.8500\n",
      "Epoch 76/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8108 - val_loss: 0.8490\n",
      "Epoch 77/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8095 - val_loss: 0.8480\n",
      "Epoch 78/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8084 - val_loss: 0.8470\n",
      "Epoch 79/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8076 - val_loss: 0.8462\n",
      "Epoch 80/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8069 - val_loss: 0.8454\n",
      "Epoch 81/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8062 - val_loss: 0.8447\n",
      "Epoch 82/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8053 - val_loss: 0.8446\n",
      "Epoch 83/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8046 - val_loss: 0.8440\n",
      "Epoch 84/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8039 - val_loss: 0.8434\n",
      "Epoch 85/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8032 - val_loss: 0.8428\n",
      "Epoch 86/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8025 - val_loss: 0.8418\n",
      "Epoch 87/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8017 - val_loss: 0.8412\n",
      "Epoch 88/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8009 - val_loss: 0.8403\n",
      "Epoch 89/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.8001 - val_loss: 0.8395\n",
      "Epoch 90/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7990 - val_loss: 0.8388\n",
      "Epoch 91/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7977 - val_loss: 0.8380\n",
      "Epoch 92/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7967 - val_loss: 0.8373\n",
      "Epoch 93/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7959 - val_loss: 0.8370\n",
      "Epoch 94/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7952 - val_loss: 0.8368\n",
      "Epoch 95/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7946 - val_loss: 0.8363\n",
      "Epoch 96/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7938 - val_loss: 0.8357\n",
      "Epoch 97/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7928 - val_loss: 0.8352\n",
      "Epoch 98/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7920 - val_loss: 0.8349\n",
      "Epoch 99/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7914 - val_loss: 0.8346\n",
      "Epoch 100/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7908 - val_loss: 0.8348\n",
      "Epoch 101/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7900 - val_loss: 0.8340\n",
      "Epoch 102/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7888 - val_loss: 0.8337\n",
      "Epoch 103/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7878 - val_loss: 0.8334\n",
      "Epoch 104/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7869 - val_loss: 0.8326\n",
      "Epoch 105/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7860 - val_loss: 0.8319\n",
      "Epoch 106/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7854 - val_loss: 0.8317\n",
      "Epoch 107/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7849 - val_loss: 0.8314\n",
      "Epoch 108/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7842 - val_loss: 0.8312\n",
      "Epoch 109/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7836 - val_loss: 0.8314\n",
      "Epoch 110/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7834 - val_loss: 0.8311\n",
      "Epoch 111/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7828 - val_loss: 0.8306\n",
      "Epoch 112/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7816 - val_loss: 0.8299\n",
      "Epoch 113/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7805 - val_loss: 0.8294\n",
      "Epoch 114/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7794 - val_loss: 0.8288\n",
      "Epoch 115/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7783 - val_loss: 0.8286\n",
      "Epoch 116/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7775 - val_loss: 0.8282\n",
      "Epoch 117/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7769 - val_loss: 0.8277\n",
      "Epoch 118/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7760 - val_loss: 0.8272\n",
      "Epoch 119/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7755 - val_loss: 0.8273\n",
      "Epoch 120/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7750 - val_loss: 0.8271\n",
      "Epoch 121/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7744 - val_loss: 0.8269\n",
      "Epoch 122/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7741 - val_loss: 0.8267\n",
      "Epoch 123/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7736 - val_loss: 0.8260\n",
      "Epoch 124/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7726 - val_loss: 0.8254\n",
      "Epoch 125/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7714 - val_loss: 0.8247\n",
      "Epoch 126/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7703 - val_loss: 0.8241\n",
      "Epoch 127/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7693 - val_loss: 0.8240\n",
      "Epoch 128/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7689 - val_loss: 0.8241\n",
      "Epoch 129/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7685 - val_loss: 0.8238\n",
      "Epoch 130/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7678 - val_loss: 0.8236\n",
      "Epoch 131/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7673 - val_loss: 0.8235\n",
      "Epoch 132/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7668 - val_loss: 0.8233\n",
      "Epoch 133/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7662 - val_loss: 0.8232\n",
      "Epoch 134/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7656 - val_loss: 0.8227\n",
      "Epoch 135/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7649 - val_loss: 0.8221\n",
      "Epoch 136/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7643 - val_loss: 0.8219\n",
      "Epoch 137/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7635 - val_loss: 0.8217\n",
      "Epoch 138/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7627 - val_loss: 0.8213\n",
      "Epoch 139/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7619 - val_loss: 0.8211\n",
      "Epoch 140/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7614 - val_loss: 0.8212\n",
      "Epoch 141/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7608 - val_loss: 0.8208\n",
      "Epoch 142/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7602 - val_loss: 0.8203\n",
      "Epoch 143/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7592 - val_loss: 0.8196\n",
      "Epoch 144/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7583 - val_loss: 0.8190\n",
      "Epoch 145/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7574 - val_loss: 0.8186\n",
      "Epoch 146/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7567 - val_loss: 0.8180\n",
      "Epoch 147/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7560 - val_loss: 0.8175\n",
      "Epoch 148/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7554 - val_loss: 0.8172\n",
      "Epoch 149/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7547 - val_loss: 0.8169\n",
      "Epoch 150/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7537 - val_loss: 0.8161\n",
      "Epoch 151/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7527 - val_loss: 0.8157\n",
      "Epoch 152/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7520 - val_loss: 0.8159\n",
      "Epoch 153/200\n",
      "800167/800167 [==============================] - 0s 0us/step - loss: 0.7516 - val_loss: 0.8158\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_x,train_y,batch_size = 100000,epochs =200,callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=0)],validation_data=(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=model.predict([testdata[\"UserID\"].values,testdata[\"MovieID\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100021/100021 [==============================] - 3s 30us/step\n"
     ]
    }
   ],
   "source": [
    "test=model.evaluate([testdata[\"UserID\"].values,testdata[\"MovieID\"].values],testdata[\"Rating\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808710118883095"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='./img/model_p.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 绘制训练 & 验证的准确率值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig(\"./img/model_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5005, 4983, 4785, ..., 4868, 4907, 5530], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
